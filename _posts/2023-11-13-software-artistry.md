A recurrent question in my role CTO is: how much process does your engineering team actually need?

As someone who formally studied Software Engineering at Carnegie Mellon University's Master of Software Engineering with the explicit goal of developing engineering leadership capabilities and systematic problem solving, I ended up identifiying two biases one should be wary of:

1) The strong belief that "good software engineering is an art", i.e. something shapeless, formless, uncontrollable, magical almost, not achievable through any kind of empirical study or research, just by sheer ambiguous "experience", whether that experience is actually building expertise or consists of doing the same thing for 20 years, equally. This is, to be blunt, often either a beginner's attitude or that of someone who never really had to work on highly constrained, highly complex projects (scale, number of stakeholders, number of developers, etc.). It almost becomes a desire to belittle and systematically ignore any effort to quantify, study or formalize software engineering practices, preferring this fake "flexibility" and "creativity" which is really a desire not to do the work or learn from others' experiences. The packaging of this attitude varies, but I have learned to spot it. Anytime a developer (especially a junior) claims they are "a code craftsman", "a software artisan", etc. a red flag goes up. Anytime I read "method/technology X is dead", my skepticism activates. Anytime I see someone with uniform (if not an actual single one) experience tell me their theories about software development in general, and bash everything everyone else is doing, I know I'm dealing with an "artisan", not an engineer. Don't get me wrong, an artisan will do some things great, they could write beautiful well-structured code, they could build systems that work as desired by their clients, but most of the time they'll take a lot longer to do so than if they sought actual lessons learned from peers and literature. You can figure out the SOLID principles on your own, they may help you if the problem setup is right, but you could conversely reach that end point much faster if you just read them and saw some examples instead of squeezing them out of your brain after a handful of projects.

2) The strong belief that "without (my favorite) formalized, explicit, heavy, tracked process we're done". I may have sounded like this type in the previous paragraph, the way I describe the whole problem. Notice however how I started the description of this point which is "the strong belief", It has to be a belief and it has to be strong. I believe as I mean it in this context is an unjustified strong conviction that is more based in irrational thought thought then in actual study and learning. I'm sure you have encountered this multiple times in throughout your career where someone would be a zealot for a certain methodology and can never see the criticism that people may raise against it. Their conviction is oftentimes so strong that it does not accept any criticism or discussion of the methodology they so strongly believe in, and that's where the qualifier "strong" comes from. It is OK to adopt a certain methodology that works for most of your use cases and to reflect upon its advantages over other methodologies and how it's making your process more streamlined and your coding easier. Where most developers go wrong is trying to generalize a methodology that they know or like as being the best over "software engineering" in general, flattening all of its facets and the diverse problems it solves, exactly just because they like. Extrapolation must be exercised with extreme care, and understanding that sometimes the simple "let's eyeball it" is enough for most PoCs (Proofs of Concept) and small enough tasks/projects is key. You don't need a full project structure and process to produce a PoC the goal of which is to dip your team's toes in a new technology or way of doing things.

How does this fit with the picture of a startup?

Startups are known for the "quick and dirty" aka. "move fast and break things" style of work, "fail early fail fast", which were funny enough adages pulled out of the context where they make sense (Software QA) and generalized into pitch decks for VCs. In the business sense, there is some meaning to this. However, using that as a reason to not adopt any process or structure is often a mistake. I always come back to my favorite quote from the movie body of lies, which is "Urgency does not call for changing methods that work, for methods that do not work.". Indeed, many times the feeling of urgency would have you chasing the target the wrong way, and the imperative to deliver on those work items urgently would have you going down the wrong path for so long that you lose sight of the actual goals. Ironically, moving fast and breaking things can turn into delaying a realization deliberately because of not questioning the current path. Stubbornly prioritizing building and showing something something for it over thinking of what you're building and how it is relevant to your goals is a mistake I've seen done so many times, from large companies to startups. A certain amount of failure and learning is acceptable of course, that is the very core of any engineering approach. The problem arises when the imperative to deliver has teams skipping over the very important phase of thinking of the "why" of it all and the "how" of it all, as related to the "why". In other terms: skipping over things like requirements engineering and architecture design and jumping right into coding a vaguely understood solution.

I draw the line at PoCs. PoCs don't need as much forethought as full projects or products, they often just aim to prove a few possibilities or a statement of feasibility. In that sense, quick and dirty is the way to go, with the understanding (oh so elusive still) that the outcome is not a working product and must not just be pushed to production.

So as the CTO, how much process does my engineering team need?

I guess I have already answered the question, but anything beyong a PoC needs some process. "Some process" is vague enough, but the rule of thumb is: if you and your team still don't have a good understanding/consensus on the "why" or the "how" of it all, there's a lack in your process. It doesn't mean "add forms, spreadsheets and meetings and it will fix itself". It means sit down with your team, identify ambiguities, why they have still managed to stay ambiguous and add activities in your pipeline that aim to effectively and systematically lift the ambiguity.

In my most recent couple of experiences, where the teams are building web/mobile apps, I found myself setting up processes that start as a simple Kanban process and grow into a more "lightweight" scrum where priorities and understanding of stories and tasks take the center stage to things like estimation. The cost of bad prioritization and bad understanding or translation of requirements into "developer tasks" has proven much higher than the one of "bad estimates". Quite often actually, bad estimates originate from a bad understanding of requirements.

But wait, that answers question #2, but how about question #1?

I am by no means advocating for firing all of your "artisan engineers". They do add value and they do have a place within teams provided they do not disrupt the process or the flow of things too much especially if they're very vocal and critical of everything and everyone else. If you have an artisan on your team, provide them with enough space to be creative and to be to do things as they like them to be done. Just make sure they understand what is expected of them, quality constraints, correctness to the requirements, etc. Ideally, that would mean giving them a piece of the software to build that is highly decoupled from all other pieces and does not require intense collaboration with other colleagues. That is where many artisans (true ones) actually shine and provide high value.